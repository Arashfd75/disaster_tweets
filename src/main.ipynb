{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('disaster_tweet')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n disaster_tweet ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "import gc\n",
    "import re\n",
    "import string\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "!pip3 install pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import model\n",
    "# import tokenization\n",
    "# from wordcloud import STOPWORDS\n",
    "\n",
    "# from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.optimizers import SGD, Adam\n",
    "# from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling1D\n",
    "# from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "\n",
    "\n",
    "missing_cols = ['keyword', 'location']\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(17, 4), dpi=100)\n",
    "\n",
    "sns.barplot(x=model.df_train[missing_cols].isnull().sum().index, y=model.df_train[missing_cols].isnull().sum().values, ax=axes[0])\n",
    "sns.barplot(x=model.df_test[missing_cols].isnull().sum().index, y=model.df_test[missing_cols].isnull().sum().values, ax=axes[1])\n",
    "axes[0].set_ylabel('Missing Value Count', size=15, labelpad=20)\n",
    "axes[0].set_title('Training Set', fontsize=13)\n",
    "axes[1].set_title('Test Set', fontsize=13)\n",
    "print(f\"Percentage of missing data in Train: {100 * model.df_train[missing_cols].isna().sum() / model.df_train[missing_cols].count()}\" )\n",
    "print(f\"Percentage of missing data in Test: {100 * model.df_test[missing_cols].isna().sum() / model.df_test[missing_cols].count()}\" )\n",
    "# plt.show()\n",
    "print( model.df_train[missing_cols].count())\n",
    "print(model.df_train[missing_cols].isna().sum())\n",
    "\n",
    "for df in [model.df_train, model.df_test]:\n",
    "    for col in ['keyword', 'location']:\n",
    "        df[col] = df[col].fillna(f'no_{col}')\n",
    "\n",
    "\n",
    "print(f'Number of unique values in keyword = {model.df_train[\"keyword\"].nunique()} (Training) - {model.df_test[\"keyword\"].nunique()} (Test)')\n",
    "print(f'Number of unique values in location = {model.df_train[\"location\"].nunique()} (Training) - {model.df_test[\"location\"].nunique()} (Test)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ('disaster_tweet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
